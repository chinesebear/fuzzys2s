{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class Weight(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Weight, self).__init__()\n",
    "        self.w = nn.Parameter(torch.tensor([0.5]))\n",
    "        self.delta = nn.Parameter(torch.randn(8,8))\n",
    "    def forward(self,x):\n",
    "        output = x + self.delta[0]\n",
    "        return output*self.w\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,feature_num , rule_num, center,sigma ):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc = nn.Linear(feature_num, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop_out= nn.Dropout(0.1)\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.drop_out2= nn.Dropout(0.1)\n",
    "        self.fc3 = nn.Linear(16, 8)\n",
    "        self.weight = Weight()\n",
    "    def forward(self, x):\n",
    "        input = self.fc(x)\n",
    "        input = self.relu(input)\n",
    "        input = self.drop_out(input)\n",
    "        input = self.fc2(input)\n",
    "        input = self.relu2(input)\n",
    "        input = self.drop_out2(input)\n",
    "        output = self.fc3(input)\n",
    "        return self.weight(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = torch.randn((100, 13))\n",
    "target = torch.randint(0,5, (100,1))\n",
    "\n",
    "mlp = MLP(13,10, \"\",\"\")\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0001, weight_decay=0)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for i in range(100):\n",
    "    x = torch.tensor(features[i])\n",
    "    target = torch.tensor(target[i]).squeeze()\n",
    "    output = mlp(x)\n",
    "    loss = criterion(output, target)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    for name, parms in mlp.named_parameters():\n",
    "        print('-->name:', name)\n",
    "        # print('-->para:', parms)\n",
    "        print('-->grad_requirs:',parms.requires_grad)\n",
    "        print('-->grad_value:',parms.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n",
      "tensor([[0, 1, 2, 3, 4, 5, 6, 7],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([0,1,2,3,4,5,6,7])\n",
    "# x = x.view(1,-1)\n",
    "print(x)\n",
    "x_arr = x.repeat(1, 10).view(-1, 8)\n",
    "print(x_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2000, 0.2000, 0.3000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
      "        0.4000])\n",
      "tensor([0.2000, 0.4000, 0.9000, 1.6000, 2.0000, 2.4000, 2.8000, 3.2000, 3.6000,\n",
      "        4.0000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "rule = torch.tensor([1,2,3,4,5,6,7,8,9,10])\n",
    "memory = torch.tensor([2,2,3,4,4,4,4,4,4,4])\n",
    "recurrent_weight = torch.tensor([0.1,0.1, 0.1,0.1,0.1,0.1, 0.1,0.1,0.1,0.1])\n",
    "recurrent_memory = torch.mul(memory, recurrent_weight)\n",
    "print(recurrent_memory)\n",
    "rule = torch.mul(rule, recurrent_memory)\n",
    "print(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 ,coutn: 10 ,loss: 0.7715085506439209\n",
      "epoch: 19 ,coutn: 20 ,loss: 0.7626175701618194\n",
      "epoch: 29 ,coutn: 30 ,loss: 0.780062468846639\n",
      "epoch: 39 ,coutn: 40 ,loss: 0.7694632485508919\n",
      "epoch: 49 ,coutn: 50 ,loss: 0.7649408495426178\n",
      "epoch: 59 ,coutn: 60 ,loss: 0.7622565160195033\n",
      "epoch: 69 ,coutn: 70 ,loss: 0.7642722879137311\n",
      "epoch: 79 ,coutn: 80 ,loss: 0.7611402288079262\n",
      "epoch: 89 ,coutn: 90 ,loss: 0.7602542943424648\n",
      "epoch: 99 ,coutn: 100 ,loss: 0.7574954503774642\n",
      "epoch: 9 ,coutn: 10 ,loss: 0.7392565667629242\n",
      "epoch: 19 ,coutn: 20 ,loss: 0.721653938293457\n",
      "epoch: 29 ,coutn: 30 ,loss: 0.7371583660443624\n",
      "epoch: 39 ,coutn: 40 ,loss: 0.7278724819421768\n",
      "epoch: 49 ,coutn: 50 ,loss: 0.7240020215511322\n",
      "epoch: 59 ,coutn: 60 ,loss: 0.7199669847885768\n",
      "epoch: 69 ,coutn: 70 ,loss: 0.7241948579038893\n",
      "epoch: 79 ,coutn: 80 ,loss: 0.719625560939312\n",
      "epoch: 89 ,coutn: 90 ,loss: 0.7207553519142998\n",
      "epoch: 99 ,coutn: 100 ,loss: 0.7170013153553009\n",
      "epoch: 9 ,coutn: 10 ,loss: 0.6854872584342957\n",
      "epoch: 19 ,coutn: 20 ,loss: 0.6895570188760758\n",
      "epoch: 29 ,coutn: 30 ,loss: 0.697224634885788\n",
      "epoch: 39 ,coutn: 40 ,loss: 0.6833916947245597\n",
      "epoch: 49 ,coutn: 50 ,loss: 0.6768218410015107\n",
      "epoch: 59 ,coutn: 60 ,loss: 0.6723518679539363\n",
      "epoch: 69 ,coutn: 70 ,loss: 0.6738697145666395\n",
      "epoch: 79 ,coutn: 80 ,loss: 0.6676852021366357\n",
      "epoch: 89 ,coutn: 90 ,loss: 0.6669060366021262\n",
      "epoch: 99 ,coutn: 100 ,loss: 0.664412708580494\n",
      "epoch: 9 ,coutn: 10 ,loss: 0.6687951505184173\n",
      "epoch: 19 ,coutn: 20 ,loss: 0.6394863277673721\n",
      "epoch: 29 ,coutn: 30 ,loss: 0.6469037473201752\n",
      "epoch: 39 ,coutn: 40 ,loss: 0.643891666829586\n",
      "epoch: 49 ,coutn: 50 ,loss: 0.6360208344459534\n",
      "epoch: 59 ,coutn: 60 ,loss: 0.6301062847177188\n",
      "epoch: 69 ,coutn: 70 ,loss: 0.6287001818418503\n",
      "epoch: 79 ,coutn: 80 ,loss: 0.6262750744819641\n",
      "epoch: 89 ,coutn: 90 ,loss: 0.6245389931731754\n",
      "epoch: 99 ,coutn: 100 ,loss: 0.6206575641036034\n",
      "epoch: 9 ,coutn: 10 ,loss: 0.5978816032409668\n",
      "epoch: 19 ,coutn: 20 ,loss: 0.5890035063028336\n",
      "epoch: 29 ,coutn: 30 ,loss: 0.6005049347877502\n",
      "epoch: 39 ,coutn: 40 ,loss: 0.588338565826416\n",
      "epoch: 49 ,coutn: 50 ,loss: 0.5812340247631073\n",
      "epoch: 59 ,coutn: 60 ,loss: 0.5750438561042149\n",
      "epoch: 69 ,coutn: 70 ,loss: 0.5770488125937325\n",
      "epoch: 79 ,coutn: 80 ,loss: 0.5722929362207652\n",
      "epoch: 89 ,coutn: 90 ,loss: 0.5731180565224754\n",
      "epoch: 99 ,coutn: 100 ,loss: 0.5714284685254097\n",
      "epoch: 9 ,coutn: 10 ,loss: 0.5447180688381195\n",
      "epoch: 19 ,coutn: 20 ,loss: 0.5406995072960854\n",
      "epoch: 29 ,coutn: 30 ,loss: 0.552318948507309\n",
      "epoch: 39 ,coutn: 40 ,loss: 0.539524532854557\n",
      "epoch: 49 ,coutn: 50 ,loss: 0.5403811359405517\n",
      "epoch: 59 ,coutn: 60 ,loss: 0.5408878564834595\n",
      "epoch: 69 ,coutn: 70 ,loss: 0.5388761882271086\n",
      "epoch: 79 ,coutn: 80 ,loss: 0.5406963501125575\n",
      "epoch: 89 ,coutn: 90 ,loss: 0.5423572407828436\n",
      "epoch: 99 ,coutn: 100 ,loss: 0.5391571474075317\n",
      "epoch: 9 ,coutn: 10 ,loss: 0.49356909096241\n",
      "epoch: 19 ,coutn: 20 ,loss: 0.4863234505057335\n",
      "epoch: 29 ,coutn: 30 ,loss: 0.49487962424755094\n",
      "epoch: 39 ,coutn: 40 ,loss: 0.49044371470808984\n",
      "epoch: 49 ,coutn: 50 ,loss: 0.48775811135768893\n",
      "epoch: 59 ,coutn: 60 ,loss: 0.48258053312699\n",
      "epoch: 69 ,coutn: 70 ,loss: 0.4823835143021175\n",
      "epoch: 79 ,coutn: 80 ,loss: 0.4801701057702303\n",
      "epoch: 89 ,coutn: 90 ,loss: 0.481189935737186\n",
      "epoch: 99 ,coutn: 100 ,loss: 0.4819797709584236\n",
      "epoch: 9 ,coutn: 10 ,loss: 0.4742622196674347\n",
      "epoch: 19 ,coutn: 20 ,loss: 0.4570946767926216\n",
      "epoch: 29 ,coutn: 30 ,loss: 0.46036754647890726\n",
      "epoch: 39 ,coutn: 40 ,loss: 0.4527189306914806\n",
      "epoch: 49 ,coutn: 50 ,loss: 0.446821545958519\n",
      "epoch: 59 ,coutn: 60 ,loss: 0.4416216010848681\n",
      "epoch: 69 ,coutn: 70 ,loss: 0.44145991717066085\n",
      "epoch: 79 ,coutn: 80 ,loss: 0.4361707057803869\n",
      "epoch: 89 ,coutn: 90 ,loss: 0.4357997967137231\n",
      "epoch: 99 ,coutn: 100 ,loss: 0.4333179301023483\n",
      "epoch: 9 ,coutn: 10 ,loss: 0.42976116836071016\n",
      "epoch: 19 ,coutn: 20 ,loss: 0.43280399292707444\n",
      "epoch: 29 ,coutn: 30 ,loss: 0.4459329436222712\n",
      "epoch: 39 ,coutn: 40 ,loss: 0.43484297916293146\n",
      "epoch: 49 ,coutn: 50 ,loss: 0.42802843272686003\n",
      "epoch: 59 ,coutn: 60 ,loss: 0.4199326867858569\n",
      "epoch: 69 ,coutn: 70 ,loss: 0.4181131912129266\n",
      "epoch: 79 ,coutn: 80 ,loss: 0.4113918267190456\n",
      "epoch: 89 ,coutn: 90 ,loss: 0.4063691433933046\n",
      "epoch: 99 ,coutn: 100 ,loss: 0.4039534404873848\n",
      "epoch: 9 ,coutn: 10 ,loss: 0.3781062036752701\n",
      "epoch: 19 ,coutn: 20 ,loss: 0.37984125390648843\n",
      "epoch: 29 ,coutn: 30 ,loss: 0.3829744910200437\n",
      "epoch: 39 ,coutn: 40 ,loss: 0.37519411109387873\n",
      "epoch: 49 ,coutn: 50 ,loss: 0.3705176129937172\n",
      "epoch: 59 ,coutn: 60 ,loss: 0.3616829372942448\n",
      "epoch: 69 ,coutn: 70 ,loss: 0.3595297479203769\n",
      "epoch: 79 ,coutn: 80 ,loss: 0.35307764541357756\n",
      "epoch: 89 ,coutn: 90 ,loss: 0.3547990658217006\n",
      "epoch: 99 ,coutn: 100 ,loss: 0.35367036759853365\n",
      "epoch: 9 ,coutn: 10 ,loss: 0.3274130880832672\n",
      "epoch: 19 ,coutn: 20 ,loss: 0.3383451223373413\n",
      "epoch: 29 ,coutn: 30 ,loss: 0.3449838250875473\n",
      "epoch: 39 ,coutn: 40 ,loss: 0.32973993942141533\n",
      "epoch: 49 ,coutn: 50 ,loss: 0.3255197075009346\n",
      "epoch: 59 ,coutn: 60 ,loss: 0.3230967919031779\n",
      "epoch: 69 ,coutn: 70 ,loss: 0.3165050800357546\n",
      "epoch: 79 ,coutn: 80 ,loss: 0.31213234197348355\n",
      "epoch: 89 ,coutn: 90 ,loss: 0.3088322091433737\n",
      "epoch: 99 ,coutn: 100 ,loss: 0.3098776459693909\n",
      "epoch: 9 ,coutn: 10 ,loss: 0.32774989157915113\n",
      "epoch: 19 ,coutn: 20 ,loss: 0.3129298806190491\n",
      "epoch: 29 ,coutn: 30 ,loss: 0.30971989532311756\n",
      "epoch: 39 ,coutn: 40 ,loss: 0.2969110541045666\n",
      "epoch: 49 ,coutn: 50 ,loss: 0.28851853758096696\n",
      "epoch: 59 ,coutn: 60 ,loss: 0.2840895541012287\n",
      "epoch: 69 ,coutn: 70 ,loss: 0.2842059490936143\n",
      "epoch: 79 ,coutn: 80 ,loss: 0.281111559458077\n",
      "epoch: 89 ,coutn: 90 ,loss: 0.27786175161600113\n",
      "epoch: 99 ,coutn: 100 ,loss: 0.277767566293478\n",
      "epoch: 9 ,coutn: 10 ,loss: 0.2598799839615822\n",
      "epoch: 19 ,coutn: 20 ,loss: 0.25487999618053436\n",
      "epoch: 29 ,coutn: 30 ,loss: 0.2585334817568461\n",
      "epoch: 39 ,coutn: 40 ,loss: 0.2461287759244442\n",
      "epoch: 49 ,coutn: 50 ,loss: 0.2408618488907814\n",
      "epoch: 59 ,coutn: 60 ,loss: 0.2406001163025697\n",
      "epoch: 69 ,coutn: 70 ,loss: 0.24074300697871617\n",
      "epoch: 79 ,coutn: 80 ,loss: 0.2355423580855131\n",
      "epoch: 89 ,coutn: 90 ,loss: 0.23532950497335858\n",
      "epoch: 99 ,coutn: 100 ,loss: 0.2355665812641382\n",
      "epoch: 9 ,coutn: 10 ,loss: 0.2294012077152729\n",
      "epoch: 19 ,coutn: 20 ,loss: 0.21854976639151574\n",
      "epoch: 29 ,coutn: 30 ,loss: 0.21946245630582173\n",
      "epoch: 39 ,coutn: 40 ,loss: 0.21736710257828235\n",
      "epoch: 49 ,coutn: 50 ,loss: 0.21192832693457603\n",
      "epoch: 59 ,coutn: 60 ,loss: 0.2109429447601239\n",
      "epoch: 69 ,coutn: 70 ,loss: 0.2088453695178032\n",
      "epoch: 79 ,coutn: 80 ,loss: 0.20503720808774234\n",
      "epoch: 89 ,coutn: 90 ,loss: 0.20516395039028593\n",
      "epoch: 99 ,coutn: 100 ,loss: 0.20506755247712136\n",
      "epoch: 9 ,coutn: 10 ,loss: 0.21013202294707298\n",
      "epoch: 19 ,coutn: 20 ,loss: 0.2156733486801386\n",
      "epoch: 29 ,coutn: 30 ,loss: 0.20614003762602806\n",
      "epoch: 39 ,coutn: 40 ,loss: 0.1940486028790474\n",
      "epoch: 49 ,coutn: 50 ,loss: 0.18860694020986557\n",
      "epoch: 59 ,coutn: 60 ,loss: 0.18381172666947046\n",
      "epoch: 69 ,coutn: 70 ,loss: 0.18571728404079166\n",
      "epoch: 79 ,coutn: 80 ,loss: 0.1802176578901708\n",
      "epoch: 89 ,coutn: 90 ,loss: 0.18310458055800863\n",
      "epoch: 99 ,coutn: 100 ,loss: 0.18304129309952258\n",
      "epoch: 9 ,coutn: 10 ,loss: 0.18217385038733483\n",
      "epoch: 19 ,coutn: 20 ,loss: 0.17507926151156425\n",
      "epoch: 29 ,coutn: 30 ,loss: 0.18619740108648936\n",
      "epoch: 39 ,coutn: 40 ,loss: 0.17363573405891658\n",
      "epoch: 49 ,coutn: 50 ,loss: 0.16629516765475272\n",
      "epoch: 59 ,coutn: 60 ,loss: 0.15865295963982742\n",
      "epoch: 69 ,coutn: 70 ,loss: 0.1558537609875202\n",
      "epoch: 79 ,coutn: 80 ,loss: 0.15812554759904743\n",
      "epoch: 89 ,coutn: 90 ,loss: 0.15766393269101778\n",
      "epoch: 99 ,coutn: 100 ,loss: 0.1588366787135601\n",
      "epoch: 9 ,coutn: 10 ,loss: 0.16367274671792983\n",
      "epoch: 19 ,coutn: 20 ,loss: 0.1460146026685834\n",
      "epoch: 29 ,coutn: 30 ,loss: 0.1565356740107139\n",
      "epoch: 39 ,coutn: 40 ,loss: 0.14533638106659055\n",
      "epoch: 49 ,coutn: 50 ,loss: 0.13804252400994302\n",
      "epoch: 59 ,coutn: 60 ,loss: 0.13352322441836198\n",
      "epoch: 69 ,coutn: 70 ,loss: 0.13434948133570807\n",
      "epoch: 79 ,coutn: 80 ,loss: 0.13086265372112393\n",
      "epoch: 89 ,coutn: 90 ,loss: 0.13110407375627095\n",
      "epoch: 99 ,coutn: 100 ,loss: 0.13365281254053116\n",
      "epoch: 9 ,coutn: 10 ,loss: 0.12837728001177312\n",
      "epoch: 19 ,coutn: 20 ,loss: 0.12445911802351475\n",
      "epoch: 29 ,coutn: 30 ,loss: 0.1313868356247743\n",
      "epoch: 39 ,coutn: 40 ,loss: 0.12074695453047753\n",
      "epoch: 49 ,coutn: 50 ,loss: 0.12097852781414986\n",
      "epoch: 59 ,coutn: 60 ,loss: 0.1167163945734501\n",
      "epoch: 69 ,coutn: 70 ,loss: 0.119431539571711\n",
      "epoch: 79 ,coutn: 80 ,loss: 0.1173069919925183\n",
      "epoch: 89 ,coutn: 90 ,loss: 0.11845418136152956\n",
      "epoch: 99 ,coutn: 100 ,loss: 0.1177603418007493\n",
      "epoch: 9 ,coutn: 10 ,loss: 0.11167455427348613\n",
      "epoch: 19 ,coutn: 20 ,loss: 0.11233084052801132\n",
      "epoch: 29 ,coutn: 30 ,loss: 0.11241611440976461\n",
      "epoch: 39 ,coutn: 40 ,loss: 0.10940361591055989\n",
      "epoch: 49 ,coutn: 50 ,loss: 0.11093977011740208\n",
      "epoch: 59 ,coutn: 60 ,loss: 0.10762097102900346\n",
      "epoch: 69 ,coutn: 70 ,loss: 0.10533767363854817\n",
      "epoch: 79 ,coutn: 80 ,loss: 0.1024497953709215\n",
      "epoch: 89 ,coutn: 90 ,loss: 0.1008039145419995\n",
      "epoch: 99 ,coutn: 100 ,loss: 0.10176451794803143\n",
      "epoch: 9 ,coutn: 10 ,loss: 0.11159570030868053\n",
      "epoch: 19 ,coutn: 20 ,loss: 0.10112773543223738\n",
      "epoch: 29 ,coutn: 30 ,loss: 0.10320291835814714\n",
      "epoch: 39 ,coutn: 40 ,loss: 0.099346694489941\n",
      "epoch: 49 ,coutn: 50 ,loss: 0.09928534355014562\n",
      "epoch: 59 ,coutn: 60 ,loss: 0.09599072880422076\n",
      "epoch: 69 ,coutn: 70 ,loss: 0.09286826181092432\n",
      "epoch: 79 ,coutn: 80 ,loss: 0.08986417055130005\n",
      "epoch: 89 ,coutn: 90 ,loss: 0.08840482859975762\n",
      "epoch: 99 ,coutn: 100 ,loss: 0.09013928599655628\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,feature_num , rule_num):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc = nn.Linear(feature_num, 32)\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop_out= nn.Dropout(0.1)\n",
    "        self.fc3 = nn.Linear(16, 2)\n",
    "    def forward(self, x):\n",
    "        input = self.fc(x)\n",
    "        input = self.fc2(input)\n",
    "        input = self.relu(input)\n",
    "        input = self.drop_out(input)\n",
    "        output = self.fc3(input)\n",
    "        return output\n",
    "\n",
    "model = MLP(13, 10)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001,weight_decay=0)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "features= torch.randn((100, 13))\n",
    "labels = torch.randint(0,1,(100,1))\n",
    "epoch = 20\n",
    "for i in range(epoch):\n",
    "    count = 0\n",
    "    total_loss = 0\n",
    "    for i in range(100):\n",
    "        optimizer.zero_grad()\n",
    "        x = features[i]\n",
    "        target = labels[i].squeeze()\n",
    "        output= model(x)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count = count+ 1\n",
    "        total_loss =total_loss + loss.item()\n",
    "        if count %10 ==0:\n",
    "            print(\"epoch:\",i, \",coutn:\", count, \",loss:\", total_loss/count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
