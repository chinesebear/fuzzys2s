{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"opus_euconst\",'en-fr')\n",
    "print(dataset)\n",
    "dataset = load_dataset(\"gsarti/flores_101\",'afr')\n",
    "print(dataset)\n",
    "# dataset = load_dataset(\"code_x_glue_tc_text_to_code\")\n",
    "# print(dataset)\n",
    "# dataset = load_dataset(\"lambada\")\n",
    "# print(dataset)\n",
    "dataset = load_dataset(\"oscar\", 'unshuffled_deduplicated_af')\n",
    "print(dataset)\n",
    "dataset = load_dataset(\"cnn_dailymail\", '1.0.0')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "# print(dataset)\n",
    "dataset = dataset.shuffle()\n",
    "train_iter = iter(dataset['train'])\n",
    "for i in range(3):\n",
    "    data = next(train_iter)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import json\n",
    "f = open(\"wmt14/wmt14-fr-en-train.json\",encoding = \"utf-8\")\n",
    "dataset = json.loads(f.read())\n",
    "print(dataset['dataset'],dataset['split'],dataset['config'])\n",
    "rows = dataset['rows']\n",
    "data = []\n",
    "for row in rows:\n",
    "    print(row['row_idx'])\n",
    "    tgt = row['row']['translation']['fr']\n",
    "    src = row['row']['translation']['en']\n",
    "    print(src, tgt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"tatoeba\", lang1=\"en\", lang2=\"he\", date=\"v2020-11-09\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = open(\"/home/yang/github/fuzzys2s/doc/tatoeba/fra.txt\",encoding = \"utf-8\")\n",
    "lines = fd.readlines()\n",
    "\n",
    "for line in lines[:10]:\n",
    "    sentences = line.split(\"\\t\")\n",
    "    en = sentences[0]\n",
    "    fra = sentences[1]\n",
    "    print(\"en:\", en, \"fra:\", fra)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tokens = np.empty(5, dtype = int)\n",
    "tokens.fill(7)\n",
    "print(tokens)\n",
    "arr = np.array([[1,2,3], [1,2,3]])\n",
    "print(arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
